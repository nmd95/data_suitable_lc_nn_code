{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1234649",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fodl/nimrodd_new/miniconda3/envs/req_test_env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import shutil\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from timm import create_model\n",
    "import pickle\n",
    "import random\n",
    "from data_utils import permute_elements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00b770f",
   "metadata": {},
   "source": [
    "# Utility functions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df35ded7",
   "metadata": {},
   "source": [
    "## Function: load_and_permute_data\n",
    " This function loads data from the source folder, applies a random or custom permutation to the data,\n",
    " and saves the permuted data and labels to the destination folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7476e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_permute_data(src_folder, dst_folder, perm_path=None):\n",
    "    # Generate a random permutation of the numbers from 0 to 1023 or load custom permutation\n",
    "    if perm_path:\n",
    "        with open(perm_path, 'rb') as f:\n",
    "            random_permutation = pickle.load(f)\n",
    "            print(f\"Loaded permutation from {perm_path}\")\n",
    "    else:\n",
    "        random_permutation = random.sample(range(1024), 1024)\n",
    "\n",
    "    # List of data and label file names\n",
    "    data_files = [\"train_data.pt\", \"test_data.pt\", \"val_data.pt\"]\n",
    "    label_files = [\"train_labels.pt\", \"test_labels.pt\", \"val_labels.pt\"]\n",
    "\n",
    "    # Load, permute and save data files\n",
    "    for data_file in data_files:\n",
    "        # Load the data tensor\n",
    "        data_tensor = torch.load(os.path.join(src_folder, data_file))\n",
    "\n",
    "        # Apply the permute_elements function\n",
    "        permuted_data_tensor = permute_elements(data_tensor, random_permutation)\n",
    "\n",
    "        # Save the permuted data tensor to the destination folder\n",
    "        torch.save(permuted_data_tensor, os.path.join(dst_folder, data_file))\n",
    "\n",
    "    # Load and save label files\n",
    "    for label_file in label_files:\n",
    "        # Load the label tensor\n",
    "        label_tensor = torch.load(os.path.join(src_folder, label_file))\n",
    "\n",
    "        # Save the label tensor to the destination folder\n",
    "        torch.save(label_tensor, os.path.join(dst_folder, label_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96ea927",
   "metadata": {},
   "source": [
    "# Step 1: Create a randomly permuted version of the dataset cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf3dcc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_folder = \"user_datasets/cifar10_binary\"\n",
    "dst_folder = \"user_datasets/cifar10_binary_rand_perm\"\n",
    "perm_path = None\n",
    "\n",
    "if os.path.exists(dst_folder):\n",
    "    shutil.rmtree(dst_folder)  # Deletes the contents of the folder\n",
    "\n",
    "os.makedirs(dst_folder)  # Creates the folder\n",
    "\n",
    "load_and_permute_data(src_folder, dst_folder, perm_path=perm_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca36265",
   "metadata": {},
   "source": [
    "# Step 2: Measure entropy for the different rearrangements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d6777f",
   "metadata": {},
   "source": [
    "# Measuring: Original data\n",
    "To do this, change the 'data_dir_name' field in the yaml config files \n",
    "'configs/cifar10_binary_measure_entropy_config.yaml'\n",
    "to cifar10_binary. Then, run the following commands: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ab870f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 measure_entropy.py configs/cifar10_binary_measure_entropy_config.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "73f1a953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'level_1': 0.24817007035017014, 'level_2': 0.062260269245598465}\n"
     ]
    }
   ],
   "source": [
    "save_add = \"user_datasets/cifar10_binary/per_level_entanglement_entropies.pkl\" # for surrogate change this to 'per_level_surrogate_entropies'\n",
    "with open(save_add, 'rb') as f:\n",
    "    entropy_measurement = pickle.load(f)\n",
    "print(entropy_measurement)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3859db76",
   "metadata": {},
   "source": [
    "# Measuring: Randomly permuted data\n",
    "To do this, change the 'data_dir_name' field in the yaml config files \n",
    "'configs/cifar10_binary_measure_entropy_config.yaml'\n",
    "to cifar10_binary_rand_perm. Then, run the following commands: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b222ecb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 measure_entropy.py configs/cifar10_binary_measure_entropy_config.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a9fae002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'level_1': 0.41364074498414993, 'level_2': 0.08126604394055903}\n"
     ]
    }
   ],
   "source": [
    "save_add = \"user_datasets/cifar10_binary_rand_perm/per_level_entanglement_entropies.pkl\"\n",
    "with open(save_add, 'rb') as f:\n",
    "    entropy_measurement = pickle.load(f)\n",
    "print(entropy_measurement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b661484",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
